{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time, sys\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pickle import dump, load\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from application import App\n",
    "from actions import Actions\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "DIM = 3\n",
    "available_actions = Actions.ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "app = App(DIM)\n",
    "\n",
    "temp = ['<start>', '<end>']\n",
    "for action in available_actions:\n",
    "    temp.append(action)\n",
    "            \n",
    "app.restApp()\n",
    "print('finish')\n",
    "\n",
    "action2int = {word:i for i, word in enumerate(temp)}\n",
    "int2action = {value:key for key, value in action2int.items()}\n",
    "del temp\n",
    "                              \n",
    "                    \n",
    "print('finish!')\n",
    "app.quit(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d51bc8f2444a5daa19fca91df43c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6878\n",
      "75266 8363\n",
      "75266 8363\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "app = App(DIM)\n",
    "\n",
    "\n",
    "actionsStatesStorage = {}\n",
    "count = 0\n",
    "for _ in tqdm(range(100000)):\n",
    "    # make some actions\n",
    "    iteration = rd.randint(1,20)\n",
    "    app.manyActionsState(iteration)\n",
    "    merged = list(itertools.chain(*app.myMasterAsInt.tolist()))\n",
    "    merged = list(itertools.chain(*merged))\n",
    "    key = merged.__str__()\n",
    "    actionsList = ['<start>'] + app.reversedOppositeActions + ['<end>']\n",
    "    \n",
    "    if len(actionsList) > 2:\n",
    "        if key not in actionsStatesStorage:\n",
    "            actionsStatesStorage[key] = []\n",
    "            actionsStatesStorage[key].append(actionsList)\n",
    "        else:\n",
    "            if actionsList not in actionsStatesStorage[key]:\n",
    "                actionsStatesStorage[key].append(actionsList)\n",
    "        \n",
    "    if app.num_solved_sides() == 2:\n",
    "        count += 1\n",
    "        \n",
    "    app.restApp()\n",
    "\n",
    "print(count)\n",
    "trainSize = int(len(actionsStatesStorage) * 0.9)\n",
    "testSize = len(actionsStatesStorage) - trainSize\n",
    "\n",
    "print(trainSize, testSize)\n",
    "\n",
    "trainActionsStates = dict( list(actionsStatesStorage.items())[:trainSize] )    \n",
    "testActionsStates = dict(list(actionsStatesStorage.items())[trainSize:])\n",
    "    \n",
    "with open(\"trainActionsStates.pkl\", \"wb\") as file:\n",
    "    dump(trainActionsStates, file)\n",
    "with open(\"testActionsStates.pkl\", \"wb\") as file:\n",
    "    dump(testActionsStates, file)                               \n",
    "                              \n",
    "                               \n",
    "                               \n",
    "                               \n",
    "print(len(trainActionsStates), len(testActionsStates))\n",
    "\n",
    "\n",
    "\n",
    "del actionsStatesStorage\n",
    "print('finish!')\n",
    "app.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trainActionsStates.pkl\", \"rb\") as file:\n",
    "    trainActionsStates = load(file)\n",
    "    \n",
    "caption_length = [len(sentence) for liste in trainActionsStates.values() for sentence in liste]\n",
    "max_length = max(caption_length)\n",
    "vocab_size  = 20\n",
    "print(max_length) # maximum lenght of a caption.\n",
    "\n",
    "\n",
    "train_keys = []\n",
    "train_values = []\n",
    "for key, value in tqdm(trainActionsStates.items()):\n",
    "    \n",
    "    myKey = [int(char) for char in key[1:-1].split(', ')]\n",
    "    myValue = value\n",
    "    train_keys.append(myKey)\n",
    "    train_values.append(myValue)\n",
    "    \n",
    "\n",
    "\n",
    "with open(\"testActionsStates.pkl\", \"rb\") as file:\n",
    "    testActionsStates = load(file)    \n",
    "\n",
    "test_keys = []\n",
    "test_values = []\n",
    "for key, value in tqdm(testActionsStates.items()):\n",
    "    \n",
    "    myKey = [int(char) for char in key[1:-1].split(', ')]\n",
    "    myValue = value\n",
    "    test_keys.append(myKey)\n",
    "    test_values.append(myValue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator, intended to be used in a call to model.fit_generator()\n",
    "import sys\n",
    "\n",
    "def data_process(keys, values, batch_size):\n",
    "    partial_captions = []\n",
    "    next_words = []\n",
    "    images = []\n",
    "    total_count = 0\n",
    "    while 1:\n",
    "        \n",
    "        for key, liste in zip(keys, values):\n",
    "            current_image = key\n",
    "            \n",
    "            for sentense in liste:\n",
    "                for i in range(len(sentense)-1):\n",
    "                    total_count += 1\n",
    "                    partial = [action2int[txt] for txt in sentense[:i+1]]\n",
    "                    next = np.zeros(vocab_size)\n",
    "                    next[ action2int[sentense[i+1]] ] = 1\n",
    "\n",
    "                    partial_captions.append(partial)\n",
    "                    next_words.append(next)\n",
    "                    images.append(current_image)\n",
    "\n",
    "                    if total_count>=batch_size:\n",
    "                        next_words = np.asarray(next_words)\n",
    "                        images = np.asarray(images)\n",
    "                        partial_captions = sequence.pad_sequences(partial_captions, maxlen=max_length, padding='post')\n",
    "                        total_count = 0\n",
    "\n",
    "                        yield [[images, partial_captions], next_words]\n",
    "                        #print(images.shape, partial_captions.shape, next_words.shape)\n",
    "                        partial_captions = []\n",
    "                        next_words = []\n",
    "                        images = []\n",
    "\n",
    "\n",
    "            \n",
    "            #sys.exit()\n",
    "#data_process(train_keys, train_values, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,RepeatVector, Activation, LSTM, Embedding, Dense,Dropout, BatchNormalization, Reshape, Flatten\n",
    "from keras.layers.merge import add\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "\n",
    "\n",
    "def createModel():\n",
    "    inputs1 = Input(shape=(54,))\n",
    "    inner = Reshape((18,3,1))(inputs1)\n",
    "    inner = Conv2D(256, kernel_size=(3, 3),activation='relu')(inner)\n",
    "    inner = Flatten()(inner)\n",
    "    inner = Dense(128, activation='relu')(inner)\n",
    "    fe = RepeatVector(max_length)(inner)\n",
    "\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    inner = Embedding(vocab_size,EMBEDDING_DIM , input_length=max_length)(inputs2)\n",
    "    inner = Bidirectional(LSTM(256,return_sequences=True))(inner)\n",
    "    inner = Dropout(0.5)(inner)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    se = Dense(128)(inner)\n",
    "\n",
    "    decoder1 = add([fe, se])\n",
    "    inner = Dropout(0.5)(decoder1)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Bidirectional(LSTM(1000,return_sequences=False))(inner)\n",
    "    inner = Dense(vocab_size)(inner)\n",
    "    outputs = Activation('softmax')(inner)\n",
    "                        \n",
    "                        \n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    print (\"Model created!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = createModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "batch_size = 16\n",
    "steps_per_epoch = len(train_keys)/batch_size\n",
    "\n",
    "train_generator = data_process(train_keys, train_values, batch_size)\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=steps_per_epoch, \n",
    "                              epochs=epochs, \n",
    "                              verbose=1, \n",
    "                              callbacks=None)\n",
    "model.save('myModel.h5')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "\n",
    "\n",
    "x = [i for i in range(1, epochs +1)]\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, acc, 'b', label='Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(x, loss, 'b', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
